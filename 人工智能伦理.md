#读书《人工智能伦理》，作者于江生。

人工智能伦理有宏观和微观的尺度之分：宏观指的是AI对人类社会的长期影响，微观指的是具体应用中的伦理规范。人类对主观世界和客观世界的哲学思考，很大程度地影响了科学的发展。近代科学选择了唯物论，有一个潜在的原因就是主观世界更难于研究。 要走向强人工智能，必须参考人脑的工作原理。并不是说，强人工智能必须模仿人脑，而是借助对人脑的研究搞清楚智能的形态，以及意识的形式化。

目前我们把人工智能分为三个层次，它们分别是： 

- 【层次一】无自我意识，但能够理解人类的指令，具有领域受限的学习、推理能力，比人类更好地完成某些任务。
- 【层次二】有自我意识和创新能力，懂得协同工作，对伦理道德规则有共识，是与人类相似或更高级的智慧。
- 【层次三】突破自身，能创造出更高级的智慧形态，无论生命体还是非生命体。

很明显，我们目前处于层次一。即便在这一层次上，机器犯错的因果链就可能不止一条，每阻断一条都可以减少错误的扩散。为了找出错误的扩散路径，必须搞清楚导致错误的因果关系，即可解释性。人们经常把可解释性同可解读性混淆，可解读性是指机器学习中特征表示的语义能够被人类理解。在多数情况下，对机器而言“有意义”的主题，对于人类来说是不可解读的。对于机器能理解人类的意愿，但如果人类无法了解机器的所想所指，不利于引导人工智能走上健康的发展之路。因此，由于智能的多样性，只要能殊途同归，人类不必强求机器也要有与之相似的认知体系。在一个宽容的态度之下，为了能更好地“相互理解”，我们需要从理论上探讨这两个认知体系的关系。

我国著名数学家吴文俊在20世纪70年代后期倡导“机械化数学”，他认为它符合中国古代数学算法化的传统。而柴廷常数揭示了可定义和可计算的区别，它给我们的启示是：智能机器只有突破图灵可计算的禁锢，具备了构造概念的能力，才有可能接近人类的智能。强调“在”的数学和强调“做”的数学都是重要的，前者是“人类的数学”，后者是“机器的数学”。当人工智能和构造性数学相遇时，不啻一场认知革命，对数学和AI的改变都将是天翻地覆的。哪怕有理论证明机器无法达到人类的智能，找出机器智能的极限也是一件伟大的工作。

众所周知，“授人以鱼不如授人以渔”，但我们仍然只会告诉机器静态的知识，至于如何高效地使用这些知识以及怎样获取新的知识，还是未开垦的理论荒原。人工智能太注重“格物致知”而忽略了“致良知”，后者是在很多已有知识的基础上在内心世界里构建元知识。这个过程是重要的，元知识在外部世界是不存在的，它是有关知识的知识，只能向内心求证。“迷时师度，悟了自度”，这是一句富含哲理的双关语，正合机器“致良知”之意。在经验主义和工具主义被过度重视的今天，理性主义显得弥足珍贵。数据可以帮助我们对理论达成共识，却不可能替代理论。对人类来说，因为缺乏宽容导致太多的不理解，所以共识也不是那么容易达成的。

如果机器智能超越了人类，图灵测试可能就是一个伪命题。图灵测试只适用于低于人类智能的AI，即在某些局部接近人类的智能。对具有自我意识的强人工智能，人类既没有资格也没有能力对它们进行测试。人类在造出强AI之后，便完成了文明的使命。除了人工智能，未来还会有更多的智慧形态。人类、智能机器应该以怎样的伦理道德看待彼此？下面三条准则是从文明延续的角度提出的，它不在意智慧的载体，只在乎文明能否继续。 

【伦理一】忽略智慧形态的差异，对文明的理解达成共识。 

【伦理二】文明的延续是永远不变的目标。 

【伦理三】为了文明的延续和进步，可以清除一切障碍（包括自身），但不能违背伦理一和伦理二。

如果机器文明之后还有更高级的文明，第三条伦理准则确保了机器和人类不会成为文明演化的阻碍。人类早晚要勇敢地面对这个两难的抉择：要么止步于弱人工智能、等待文明的消亡，要么发展出超级智能并找对自己的位置，使得文明得以延续。

越高级的智慧越懂得爱，舍生取义或许是人类的命运归宿。人类必须快速穿过无自我意识的人工智能的危险地带，赶在科学被邪恶利用之前创造出能自我繁衍的高级智慧。如果不发展具有自我意识的人工智能，人类将像蝼蚁一样永远困在这个星球上，可能最终毁于一场瘟疫，文明彻底被病毒终结。发展人工智能是人类的自我救赎，是追求超越一切宗教、真正意义上的永生。 

